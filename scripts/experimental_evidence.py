"""
Experimental Evidence for Plastic Neural Networks
Ïã§ÌóòÏ†Å Ï¶ùÍ±∞ Ï∞æÍ∏∞ - PNNÏùò ÎáåÍ≥ºÌïôÏ†Å ÌÉÄÎãπÏÑ± Í≤ÄÏ¶ù

Ïù¥ Ïä§ÌÅ¨Î¶ΩÌä∏Îäî ÏÑ∏ Í∞ÄÏßÄ Ïã§ÌóòÏ†Å Ï†ëÍ∑ºÎ≤ïÏùÑ ÏãúÎÆ¨Î†àÏù¥ÏÖòÌï©ÎãàÎã§:
1. MEG (High-temporal resolution) - Gamma cycle ÎÇ¥ ÌôúÎèô Ìå®ÌÑ¥ Î∂ÑÏÑù
2. Optogenetics - ÌäπÏ†ï Îâ¥Îü∞/Î†àÏù¥Ïñ¥ ÏñµÏ†ú Ïã§Ìóò
3. Brain Activity Modeling - Î™®Îç∏ ÏòàÏ∏° vs Ïã§Ï†ú Îáå ÌôúÎèô ÎπÑÍµê

Usage:
    python scripts/experimental_evidence.py --checkpoint checkpoints/best_model.pt
    python scripts/experimental_evidence.py --checkpoint checkpoints/best_model.pt --experiment meg
    python scripts/experimental_evidence.py --checkpoint checkpoints/best_model.pt --experiment optogenetics
    python scripts/experimental_evidence.py --checkpoint checkpoints/best_model.pt --experiment modeling
"""

# Add parent directory to path for imports (makes it work without installation)
import sys
from pathlib import Path
script_dir = Path(__file__).resolve().parent
project_root = script_dir.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

import torch
import torch.nn as nn
import torch.nn.functional as F
import argparse
import json
import numpy as np
from pathlib import Path
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Optional

from pnn.models.pnn import create_pnn_model
from pnn.utils.training import load_checkpoint
from transformers import BertTokenizer
from datasets import load_dataset


# Define Config class at module level for checkpoint compatibility
class Config:
    """Dummy Config class for checkpoint loading compatibility"""
    pass


class MEGSimulator:
    """
    MEG (Magnetoencephalography) ÏãúÎÆ¨Î†àÏù¥ÏÖò

    Gamma cycle (millisecond Ìï¥ÏÉÅÎèÑ) ÎÇ¥ÏóêÏÑú ÌôúÎèô Ìå®ÌÑ¥ Î∂ÑÏÑù:
    - Ï¥àÎ∞ò: Delta generation (ÎÜíÏùÄ activity)
    - Ï§ëÎ∞ò: Gate computation (ÌäπÏ†ï Ìå®ÌÑ¥)
    - ÌõÑÎ∞ò: Update (Îã§Î•∏ Ìå®ÌÑ¥)
    """

    def __init__(self, model: nn.Module, device: str = 'cuda'):
        self.model = model
        self.device = device
        self.model.eval()

        # HookÏùÑ ÏÇ¨Ïö©Ìï¥ÏÑú Ï§ëÍ∞Ñ ÌôúÎèô Í∏∞Î°ù
        self.activations = {}
        self.register_hooks()

    def register_hooks(self):
        """Ï§ëÍ∞Ñ Î†àÏù¥Ïñ¥ ÌôúÎèôÏùÑ Í∏∞Î°ùÌïòÍ∏∞ ÏúÑÌïú hook Îì±Î°ù"""
        def get_activation(name):
            def hook(module, input, output):
                if isinstance(output, tuple):
                    output = output[0]
                self.activations[name] = output.detach()
            return hook

        # DeltaRefinerÏùò Ï£ºÏöî Ïª¥Ìè¨ÎÑåÌä∏Ïóê hook Îì±Î°ù
        self.model.delta_refiner.attention.register_forward_hook(
            get_activation('attention_output')
        )
        self.model.delta_refiner.ffn.register_forward_hook(
            get_activation('ffn_output')
        )
        self.model.delta_refiner.gate.register_forward_hook(
            get_activation('gate_output')
        )

    def simulate_gamma_cycle(
        self,
        input_ids: torch.Tensor,
        attention_mask: torch.Tensor
    ) -> Dict[str, List[torch.Tensor]]:
        """
        Gamma cycle ÏãúÎÆ¨Î†àÏù¥ÏÖò

        Í∞Å refinement stepÏùÑ gamma cycleÎ°ú Í∞ÑÏ£ºÌïòÍ≥†,
        cycle ÎÇ¥ÏóêÏÑúÏùò ÌôúÎèô Ìå®ÌÑ¥ÏùÑ Î∂ÑÏÑù

        Returns:
            step_activities: Í∞Å stepÎ≥Ñ ÌôúÎèô Ìå®ÌÑ¥
        """
        step_activities = {
            'delta_generation': [],
            'gate_computation': [],
            'hidden_update': [],
            'activity_magnitude': []
        }

        with torch.no_grad():
            # Embedding
            batch_size, seq_len = input_ids.shape
            token_embeds = self.model.token_embeddings(input_ids)
            position_ids = torch.arange(seq_len, device=input_ids.device)
            position_ids = position_ids.unsqueeze(0).expand(batch_size, -1)
            position_embeds = self.model.position_embeddings(position_ids)

            hidden = token_embeds + position_embeds
            hidden = self.model.embedding_layer_norm(hidden)
            hidden = self.model.embedding_dropout(hidden)

            attn_mask = (attention_mask == 0) if attention_mask is not None else None

            # Í∞Å refinement stepÏùÑ gamma cycleÎ°ú Î∂ÑÏÑù
            for step in range(self.model.num_steps):
                self.activations.clear()

                # Delta ÏÉùÏÑ±
                delta = self.model.delta_refiner(hidden, attn_mask)

                # ÌôúÎèô Ìå®ÌÑ¥ Í∏∞Î°ù
                # 1. Delta generation (Ï¥àÎ∞ò - ÎÜíÏùÄ activity)
                if 'ffn_output' in self.activations:
                    delta_activity = self.activations['ffn_output']
                    step_activities['delta_generation'].append(
                        delta_activity.abs().mean().cpu()
                    )

                # 2. Gate computation (Ï§ëÎ∞ò - ÌäπÏ†ï Ìå®ÌÑ¥)
                if 'gate_output' in self.activations:
                    gate_activity = self.activations['gate_output']
                    step_activities['gate_computation'].append(
                        gate_activity.mean().cpu()
                    )

                # 3. Hidden update (ÌõÑÎ∞ò)
                hidden_before = hidden.clone()
                hidden = hidden + delta
                update_magnitude = (hidden - hidden_before).abs().mean()
                step_activities['hidden_update'].append(update_magnitude.cpu())

                # Ï†ÑÏ≤¥ activity magnitude
                total_activity = delta.abs().mean()
                step_activities['activity_magnitude'].append(total_activity.cpu())

        return step_activities

    def analyze_temporal_patterns(
        self,
        dataloader,
        num_batches: int = 10
    ) -> Dict:
        """
        Ïó¨Îü¨ Î∞∞ÏπòÏóê Í±∏Ï≥ê temporal pattern Î∂ÑÏÑù

        Returns:
            analysis: ÌÜµÍ≥Ñ Î∞è Ìå®ÌÑ¥ Î∂ÑÏÑù Í≤∞Í≥º
        """
        all_activities = {
            'delta_generation': [],
            'gate_computation': [],
            'hidden_update': [],
            'activity_magnitude': []
        }

        for batch_idx, batch in enumerate(tqdm(dataloader, desc="MEG Analysis", total=num_batches)):
            if batch_idx >= num_batches:
                break

            input_ids = batch['input_ids'].to(self.device)
            attention_mask = batch['attention_mask'].to(self.device)

            activities = self.simulate_gamma_cycle(input_ids, attention_mask)

            for key in all_activities:
                all_activities[key].extend(activities[key])

        # ÌÜµÍ≥Ñ Î∂ÑÏÑù
        analysis = {}
        for key, values in all_activities.items():
            values = torch.tensor(values).numpy()
            analysis[key] = {
                'mean': float(values.mean()),
                'std': float(values.std()),
                'values': values.tolist()
            }

        return analysis


class OptogeneticsSimulator:
    """
    Optogenetics ÏãúÎÆ¨Î†àÏù¥ÏÖò

    ÌäπÏ†ï Îâ¥Îü∞/Î†àÏù¥Ïñ¥Î•º ÏñµÏ†úÌïòÏó¨ ÌñâÎèô Î≥ÄÌôî Í¥ÄÏ∞∞:
    - Attention ÏñµÏ†ú ‚Üí Delta ÏÉùÏÑ± ÎßâÌûò?
    - Gate ÏñµÏ†ú ‚Üí Update ÎßâÌûò?
    - FFN ÏñµÏ†ú ‚Üí Ï†ïÎ≥¥ Ï≤òÎ¶¨ Î≥ÄÌôî?
    """

    def __init__(self, model: nn.Module, device: str = 'cuda'):
        self.model = model
        self.device = device
        self.model.eval()

    def suppress_component(
        self,
        component: str,
        suppression_rate: float = 1.0
    ):
        """
        ÌäπÏ†ï Ïª¥Ìè¨ÎÑåÌä∏ ÏñµÏ†ú

        Args:
            component: 'attention', 'gate', 'ffn' Ï§ë ÌïòÎÇò
            suppression_rate: ÏñµÏ†ú ÎπÑÏú® (0.0 = ÏñµÏ†ú ÏóÜÏùå, 1.0 = ÏôÑÏ†Ñ ÏñµÏ†ú)
        """
        class SuppressionHook:
            def __init__(self, rate):
                self.rate = rate

            def __call__(self, module, input, output):
                if isinstance(output, tuple):
                    output = list(output)
                    output[0] = output[0] * (1.0 - self.rate)
                    return tuple(output)
                else:
                    return output * (1.0 - self.rate)

        hook = SuppressionHook(suppression_rate)

        if component == 'attention':
            handle = self.model.delta_refiner.attention.register_forward_hook(hook)
        elif component == 'gate':
            handle = self.model.delta_refiner.gate.register_forward_hook(hook)
        elif component == 'ffn':
            handle = self.model.delta_refiner.ffn.register_forward_hook(hook)
        else:
            raise ValueError(f"Unknown component: {component}")

        return handle

    def measure_behavior(
        self,
        dataloader,
        labels_key: str = 'labels',
        num_batches: int = 10
    ) -> Dict:
        """
        Î™®Îç∏ ÌñâÎèô Ï∏°Ï†ï (Ï†ïÌôïÎèÑ, ÏÜêÏã§ Îì±)

        Returns:
            metrics: ÏÑ±Îä• ÏßÄÌëú
        """
        total_loss = 0.0
        total_correct = 0
        total_tokens = 0

        with torch.no_grad():
            for batch_idx, batch in enumerate(tqdm(dataloader, desc="Measuring", total=num_batches)):
                if batch_idx >= num_batches:
                    break

                input_ids = batch['input_ids'].to(self.device)
                attention_mask = batch['attention_mask'].to(self.device)
                labels = batch[labels_key].to(self.device)

                hidden = self.model(input_ids, attention_mask)
                loss, logits = self.model.get_mlm_loss(hidden, labels)

                total_loss += loss.item()

                preds = logits.argmax(dim=-1)
                mask = (labels != -100)
                correct = (preds == labels) & mask
                total_correct += correct.sum().item()
                total_tokens += mask.sum().item()

        return {
            'loss': total_loss / num_batches,
            'accuracy': total_correct / total_tokens if total_tokens > 0 else 0,
            'total_tokens': total_tokens
        }

    def run_suppression_experiment(
        self,
        dataloader,
        num_batches: int = 10
    ) -> Dict:
        """
        Ïó¨Îü¨ Ïª¥Ìè¨ÎÑåÌä∏Ïóê ÎåÄÌïú ÏñµÏ†ú Ïã§Ìóò

        Returns:
            results: Í∞Å Ï°∞Í±¥Î≥Ñ Ïã§Ìóò Í≤∞Í≥º
        """
        results = {}

        # 1. Baseline (ÏñµÏ†ú ÏóÜÏùå)
        print("\nüìä Baseline (No suppression)...")
        results['baseline'] = self.measure_behavior(dataloader, num_batches=num_batches)

        # 2. Attention ÏñµÏ†ú
        components = ['attention', 'gate', 'ffn']
        suppression_rates = [0.25, 0.5, 0.75, 1.0]

        for component in components:
            for rate in suppression_rates:
                print(f"\nüî¨ Suppressing {component} at {rate*100:.0f}%...")

                # ÏñµÏ†ú Ï†ÅÏö©
                handle = self.suppress_component(component, rate)

                # ÌñâÎèô Ï∏°Ï†ï
                metrics = self.measure_behavior(dataloader, num_batches=num_batches)

                # Í≤∞Í≥º Ï†ÄÏû•
                key = f"{component}_suppressed_{int(rate*100)}"
                results[key] = metrics

                # ÏñµÏ†ú Ìï¥Ï†ú
                handle.remove()

        return results


class BrainActivityPredictor:
    """
    Brain Activity Modeling

    Î™®Îç∏Ïùò ÌôúÎèô Ìå®ÌÑ¥ÏùÑ ÏòàÏ∏°ÌïòÍ≥† Ïã§Ï†ú Îáå ÌôúÎèôÍ≥º ÎπÑÍµê
    (Ïã§Ï†ú fMRI/MEG Îç∞Ïù¥ÌÑ∞Í∞Ä ÏûàÎã§Î©¥ ÎπÑÍµê Í∞ÄÎä•)
    """

    def __init__(self, model: nn.Module, device: str = 'cuda'):
        self.model = model
        self.device = device
        self.model.eval()

    def extract_activation_patterns(
        self,
        dataloader,
        num_batches: int = 10
    ) -> Dict:
        """
        Î™®Îç∏Ïùò ÌôúÎèô Ìå®ÌÑ¥ Ï∂îÏ∂ú

        Returns:
            patterns: Í∞Å Î†àÏù¥Ïñ¥/Îã®Í≥ÑÎ≥Ñ ÌôúÎèô Ìå®ÌÑ¥
        """
        patterns = {
            'embeddings': [],
            'step_0': [],
            'step_1': [],
            'step_2': [],
            'step_3': [],
            'final': []
        }

        with torch.no_grad():
            for batch_idx, batch in enumerate(tqdm(dataloader, desc="Extracting patterns", total=num_batches)):
                if batch_idx >= num_batches:
                    break

                input_ids = batch['input_ids'].to(self.device)
                attention_mask = batch['attention_mask'].to(self.device)

                # Î™®Îì† stepÏùò Ï∂úÎ†• ÏñªÍ∏∞
                all_outputs = self.model(
                    input_ids,
                    attention_mask,
                    return_all_steps=True
                )

                # Í∞Å stepÏùò ÌèâÍ∑† ÌôúÎèô Ï†ÄÏû•
                patterns['embeddings'].append(all_outputs[0].mean(dim=[0, 1]).cpu().numpy())

                for step_idx in range(min(4, len(all_outputs) - 1)):
                    step_key = f'step_{step_idx}'
                    patterns[step_key].append(
                        all_outputs[step_idx + 1].mean(dim=[0, 1]).cpu().numpy()
                    )

                patterns['final'].append(all_outputs[-1].mean(dim=[0, 1]).cpu().numpy())

        # ÌèâÍ∑† Ìå®ÌÑ¥ Í≥ÑÏÇ∞
        for key in patterns:
            if patterns[key]:
                patterns[key] = np.mean(patterns[key], axis=0)

        return patterns

    def compare_with_brain_hypothesis(
        self,
        patterns: Dict
    ) -> Dict:
        """
        Í∞ÄÏÑ§Ï†Å Îáå ÌôúÎèô Ìå®ÌÑ¥Í≥º ÎπÑÍµê

        ÎáåÍ≥ºÌïô Í∞ÄÏÑ§:
        - Ï¥àÍ∏∞ step: ÎÑìÏùÄ ÌôúÎèô (ÌÉêÏÉâ)
        - Ï§ëÍ∞Ñ step: ÏÑ†ÌÉùÏ†Å ÌôúÎèô (ÏßëÏ§ë)
        - ÌõÑÍ∏∞ step: ÌÜµÌï©Ï†Å ÌôúÎèô (Ï¢ÖÌï©)
        """
        analysis = {}

        # 1. ÌôúÎèô Î≤îÏúÑ (Activity breadth) - ÌëúÏ§ÄÌé∏Ï∞®Î°ú Ï∏°Ï†ï
        for key, pattern in patterns.items():
            if isinstance(pattern, np.ndarray) and len(pattern) > 0:
                analysis[f'{key}_breadth'] = float(np.std(pattern))
                analysis[f'{key}_mean_activity'] = float(np.mean(np.abs(pattern)))

        # 2. Ìå®ÌÑ¥ Î≥ÄÌôî (Step-to-step changes)
        step_keys = ['embeddings', 'step_0', 'step_1', 'step_2', 'step_3']
        for i in range(len(step_keys) - 1):
            if step_keys[i] in patterns and step_keys[i+1] in patterns:
                p1 = patterns[step_keys[i]]
                p2 = patterns[step_keys[i+1]]
                if isinstance(p1, np.ndarray) and isinstance(p2, np.ndarray):
                    change = np.linalg.norm(p2 - p1)
                    analysis[f'change_{step_keys[i]}_to_{step_keys[i+1]}'] = float(change)

        # 3. Í∞ÄÏÑ§ Í≤ÄÏ¶ù
        # Í∞ÄÏÑ§: Ï§ëÍ∞Ñ stepÏóêÏÑú Í∞ÄÏû• ÏÑ†ÌÉùÏ†Å (ÎÇÆÏùÄ breadth)
        breadths = [
            analysis.get(f'{key}_breadth', 0)
            for key in ['step_0', 'step_1', 'step_2', 'step_3']
        ]

        if breadths:
            min_breadth_idx = np.argmin(breadths)
            analysis['most_selective_step'] = int(min_breadth_idx)
            analysis['supports_selectivity_hypothesis'] = (min_breadth_idx in [1, 2])

        return analysis


def prepare_test_data(tokenizer, num_samples: int = 100):
    """ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ"""
    from pnn.data.dataset import MLMDataset
    from torch.utils.data import DataLoader

    print("\nüìö Loading test data...")

    # WikiText-103 validation set
    dataset = load_dataset(
        "Salesforce/wikitext",
        "wikitext-103-raw-v1",
        split="validation"
    )

    test_data = []
    for item in dataset:
        text = item['text'].strip()
        if len(text) > 20 and len(text.split()) >= 5:
            test_data.append(text)
            if len(test_data) >= num_samples:
                break

    test_dataset = MLMDataset(
        tokenizer=tokenizer,
        data=test_data,
        max_length=128,
        mask_prob=0.15
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=32,
        shuffle=False,
        num_workers=0
    )

    return test_loader


def save_visualizations(results: Dict, output_dir: Path):
    """Í≤∞Í≥º ÏãúÍ∞ÅÌôî Î∞è Ï†ÄÏû•"""
    output_dir.mkdir(parents=True, exist_ok=True)

    # MEG Í≤∞Í≥º ÏãúÍ∞ÅÌôî
    if 'meg_analysis' in results:
        meg = results['meg_analysis']

        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        fig.suptitle('MEG Simulation: Temporal Activity Patterns', fontsize=16)

        for idx, (key, ax) in enumerate(zip(
            ['delta_generation', 'gate_computation', 'hidden_update', 'activity_magnitude'],
            axes.flatten()
        )):
            if key in meg and 'values' in meg[key]:
                values = meg[key]['values']
                ax.plot(values, marker='o')
                ax.set_title(f'{key.replace("_", " ").title()}')
                ax.set_xlabel('Refinement Step')
                ax.set_ylabel('Activity Magnitude')
                ax.grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(output_dir / 'meg_temporal_patterns.png', dpi=300)
        plt.close()
        print(f"\n‚úÖ Saved: {output_dir / 'meg_temporal_patterns.png'}")

    # Optogenetics Í≤∞Í≥º ÏãúÍ∞ÅÌôî
    if 'optogenetics_results' in results:
        opto = results['optogenetics_results']

        # Í∞Å Ïª¥Ìè¨ÎÑåÌä∏Î≥Ñ ÏñµÏ†ú Ìö®Í≥º
        components = ['attention', 'gate', 'ffn']
        rates = [0, 25, 50, 75, 100]

        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        fig.suptitle('Optogenetics Simulation: Suppression Effects', fontsize=16)

        for component in components:
            losses = []
            accs = []

            for rate in rates:
                if rate == 0:
                    key = 'baseline'
                else:
                    key = f'{component}_suppressed_{rate}'

                if key in opto:
                    losses.append(opto[key]['loss'])
                    accs.append(opto[key]['accuracy'] * 100)

            axes[0].plot(rates, losses, marker='o', label=component.capitalize())
            axes[1].plot(rates, accs, marker='o', label=component.capitalize())

        axes[0].set_xlabel('Suppression Rate (%)')
        axes[0].set_ylabel('Loss')
        axes[0].set_title('Loss vs Suppression Rate')
        axes[0].legend()
        axes[0].grid(True, alpha=0.3)

        axes[1].set_xlabel('Suppression Rate (%)')
        axes[1].set_ylabel('Accuracy (%)')
        axes[1].set_title('Accuracy vs Suppression Rate')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(output_dir / 'optogenetics_suppression.png', dpi=300)
        plt.close()
        print(f"‚úÖ Saved: {output_dir / 'optogenetics_suppression.png'}")

    # Brain activity Í≤∞Í≥º ÏãúÍ∞ÅÌôî
    if 'brain_hypothesis_test' in results:
        brain = results['brain_hypothesis_test']

        # Activity breadth across steps
        steps = ['embeddings', 'step_0', 'step_1', 'step_2', 'step_3', 'final']
        breadths = [brain.get(f'{s}_breadth', 0) for s in steps]
        activities = [brain.get(f'{s}_mean_activity', 0) for s in steps]

        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        fig.suptitle('Brain Activity Prediction: Pattern Analysis', fontsize=16)

        axes[0].plot(range(len(steps)), breadths, marker='o', linewidth=2)
        axes[0].set_xticks(range(len(steps)))
        axes[0].set_xticklabels(steps, rotation=45)
        axes[0].set_ylabel('Activity Breadth (std)')
        axes[0].set_title('Selectivity Across Processing Steps')
        axes[0].grid(True, alpha=0.3)

        axes[1].plot(range(len(steps)), activities, marker='o', linewidth=2, color='orange')
        axes[1].set_xticks(range(len(steps)))
        axes[1].set_xticklabels(steps, rotation=45)
        axes[1].set_ylabel('Mean Activity')
        axes[1].set_title('Activity Level Across Processing Steps')
        axes[1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(output_dir / 'brain_activity_patterns.png', dpi=300)
        plt.close()
        print(f"‚úÖ Saved: {output_dir / 'brain_activity_patterns.png'}")


def main():
    parser = argparse.ArgumentParser(
        description='Experimental Evidence for Plastic Neural Networks'
    )
    parser.add_argument(
        '--checkpoint',
        type=str,
        required=True,
        help='Path to model checkpoint (e.g., checkpoints/best_model.pt)'
    )
    parser.add_argument(
        '--experiment',
        type=str,
        default='all',
        choices=['all', 'meg', 'optogenetics', 'modeling'],
        help='Which experiment to run'
    )
    parser.add_argument(
        '--num_batches',
        type=int,
        default=10,
        help='Number of batches to analyze'
    )
    parser.add_argument(
        '--output_dir',
        type=str,
        default='results/experimental_evidence',
        help='Output directory for results'
    )
    parser.add_argument(
        '--device',
        type=str,
        default='cuda' if torch.cuda.is_available() else 'cpu',
        help='Device to use'
    )

    args = parser.parse_args()

    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    print(f"\n{'='*80}")
    print("üß† Experimental Evidence for Plastic Neural Networks")
    print(f"{'='*80}\n")

    # Load model
    print(f"üì¶ Loading checkpoint: {args.checkpoint}")

    # Create model with default config
    model_config = {
        'vocab_size': 30522,
        'hidden_size': 768,
        'num_heads': 12,
        'intermediate_size': 2048,
        'max_length': 128,
        'num_steps': 4,
        'dropout': 0.1
    }
    model = create_pnn_model(model_config)

    # Load checkpoint
    # Use weights_only=False to handle custom classes like Config
    print("üì• Loading checkpoint...")
    checkpoint = torch.load(args.checkpoint, map_location='cpu', weights_only=False)

    # Load model state dict
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        # Checkpoint might be just the state dict
        model.load_state_dict(checkpoint)

    model = model.to(args.device)
    model.eval()

    print(f"‚úÖ Model loaded on {args.device}")

    # Load tokenizer and data
    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
    test_loader = prepare_test_data(tokenizer, num_samples=args.num_batches * 32)

    results = {}

    # Experiment 1: MEG Simulation
    if args.experiment in ['all', 'meg']:
        print(f"\n{'='*80}")
        print("üî¨ Experiment 1: MEG Simulation (High-temporal resolution)")
        print(f"{'='*80}\n")

        meg_sim = MEGSimulator(model, args.device)
        meg_analysis = meg_sim.analyze_temporal_patterns(test_loader, args.num_batches)
        results['meg_analysis'] = meg_analysis

        print("\nüìä MEG Analysis Results:")
        for key, stats in meg_analysis.items():
            if isinstance(stats, dict):
                print(f"  {key}: mean={stats['mean']:.4f}, std={stats['std']:.4f}")

    # Experiment 2: Optogenetics Simulation
    if args.experiment in ['all', 'optogenetics']:
        print(f"\n{'='*80}")
        print("üî¨ Experiment 2: Optogenetics Simulation")
        print(f"{'='*80}\n")

        opto_sim = OptogeneticsSimulator(model, args.device)
        opto_results = opto_sim.run_suppression_experiment(test_loader, args.num_batches)
        results['optogenetics_results'] = opto_results

        print("\nüìä Optogenetics Results:")
        baseline_acc = opto_results['baseline']['accuracy']
        print(f"  Baseline: loss={opto_results['baseline']['loss']:.4f}, "
              f"acc={baseline_acc*100:.2f}%")

        for key, metrics in opto_results.items():
            if key != 'baseline':
                acc_drop = (baseline_acc - metrics['accuracy']) * 100
                print(f"  {key}: loss={metrics['loss']:.4f}, "
                      f"acc={metrics['accuracy']*100:.2f}% "
                      f"(drop: {acc_drop:.2f}%)")

    # Experiment 3: Brain Activity Modeling
    if args.experiment in ['all', 'modeling']:
        print(f"\n{'='*80}")
        print("üî¨ Experiment 3: Brain Activity Modeling")
        print(f"{'='*80}\n")

        brain_predictor = BrainActivityPredictor(model, args.device)
        activation_patterns = brain_predictor.extract_activation_patterns(
            test_loader, args.num_batches
        )
        hypothesis_test = brain_predictor.compare_with_brain_hypothesis(
            activation_patterns
        )

        results['activation_patterns'] = {
            k: v.tolist() if isinstance(v, np.ndarray) else v
            for k, v in activation_patterns.items()
        }
        results['brain_hypothesis_test'] = hypothesis_test

        print("\nüìä Brain Activity Analysis:")
        print(f"  Most selective step: {hypothesis_test.get('most_selective_step', 'N/A')}")
        print(f"  Supports selectivity hypothesis: "
              f"{hypothesis_test.get('supports_selectivity_hypothesis', False)}")

        for key, value in hypothesis_test.items():
            if key.endswith('_breadth'):
                print(f"  {key}: {value:.4f}")

    # Save results
    results_file = output_dir / 'experimental_results.json'
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=2)

    print(f"\nüíæ Results saved to: {results_file}")

    # Generate visualizations
    print("\nüìà Generating visualizations...")
    save_visualizations(results, output_dir)

    print(f"\n{'='*80}")
    print("‚úÖ Experimental analysis complete!")
    print(f"{'='*80}\n")
    print(f"üìÅ All results saved in: {output_dir}")
    print(f"   - experimental_results.json")
    print(f"   - meg_temporal_patterns.png")
    print(f"   - optogenetics_suppression.png")
    print(f"   - brain_activity_patterns.png")


if __name__ == "__main__":
    main()
